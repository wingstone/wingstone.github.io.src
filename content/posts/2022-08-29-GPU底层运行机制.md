---
title: 'GPU底层运行机制'
author: wingstone
date: 2022-08-29
categories:
- contents
metaAlignment: center
coverMeta: out
---

GPU底层运行机制记录

<!--more-->

**latency**是所有处理器必须要关心的事情，可以认为数据离处理器越远，等待的时间就越长。从内存上读取数据花费的时间将远大于从寄存器读取数据的时间。读取数据时，处理器将进行等待，从而产生**stall**，进而影响性能。

大部分CPU为了减小latency的影响，采用local cache的机制，使得下一步可以读取的数据尽可能在cache中。CPU还会采用其他的机制来避免stall，比如branch prediction、instruction reordering、register renaming、cache prefetching。

而GPU为了吞吐量（即可以处理的数据的量）而优化，因此GPU大部分的芯片区域都被用来放置处理器（也称shader core）了，只有很少的区域用做cache memory以及control logical，因而每个shader core的latency相比cpu来说要高很多，是尤其需要注意的问题。

对于shader来说，texture实际上属于另外的资源，并不属于可执行程序的local memory的一部分。一次texture memory fetch要花掉成百上千的时钟周期，在此期间，shader processer将导致stall。其他的非local memory fetch也会导致stall？比如structure buffer等？

GPU通过两种重要的机制来优化性能。

一种机制是simd，simd只需要花费少量的silicon以及power即可完成大量并行数据的处理，而gpu也是通过thread wrap的形式来一次处理大量线程，当遇到stall时，整个wrap都会stall，从而减少stall情况的发生。

另外一种机制是thread wrap switch，当整个wrap发生stall时，gpu会进行wrap switch切换到其他wrap，从而继续运行。当其他wrap stall时，继续切换到下一个wrap，以此来隐藏stall，从而提升gpu运行效率。warp-swapping是重要的gpu所使用的非常重要的latency-hiding机制。

Gpu thread与cpu thread不同，其包含了一部分memory用来存储shader的输入值，还包含了一部分寄存器空间，用来存储shader运行时的中间值。而gpu的寄存器数量是有限的，寄存器资源与waro是绑定的在shader运行时，因此shader使用的寄存器数量越多，gpu可切换的warp数量就越少，从而导致latency隐藏机制更容易失效，从而产生真正的stall。而可切换的warp数量被称之为**occupancy**。对于compute shader，使用的shared memory越多，同样也会造成occupancy的减少。并且在有分支的情况下，gpu是按最坏的情况来计算寄存器与memory资源的。可参考[Future Directions for Compute-for-Graphics](https://www.ea.com/seed/news/seed-siggraph2017-compute-for-graphics)

还有一个会影响gpu效率的情况是动态分支的使用（比如if、for的使用），由于gpu以warp形式运行，如果同一warp内不用thread运行了不同的分支，会导致没使用此分支的thread空闲，从而影响效率。

整个gpu基本上都是基于以上的idea进行运作，虽然在系统上有一些限制，但可以提供大量的算力。

以上总结主要参考rtr4的第3章节，而基于以上机制的优化方案，可参考rtr4上所附加的参考链接。